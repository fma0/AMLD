{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc90168f",
   "metadata": {},
   "source": [
    "# Part 2: Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47d7440",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install mne\n",
    "import mne\n",
    "from mne.decoding import Vectorizer, SlidingEstimator, cross_val_multiscore\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\n",
    "from sklearn.metrics import make_scorer, f1_score, roc_auc_score, auc, accuracy_score, balanced_accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mne.viz\n",
    "\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8dd86e",
   "metadata": {},
   "source": [
    "## Loading the data and creating train - test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ada6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "def download_file(url, outfile=None):\n",
    "    if not outfile:\n",
    "        outfile = url.split('/')[-1]\n",
    "    with requests.get(url, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        with open(outfile, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=8192): \n",
    "                f.write(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922d77fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_file('https://github.com/fma0/AMLD/blob/main/902-P.fif?raw=true', outfile='902-P.fif')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4b142f",
   "metadata": {},
   "source": [
    "### Exercise 1:\n",
    "\n",
    "1. Import the same '.fif' file as in 'Part 1: About neural data', \n",
    "2. Extract the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515b6cc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb131e67",
   "metadata": {},
   "source": [
    "If we want to extract the labels from the epochs object, we can take a look at epochs.events. This events obejct is a numpy array assaining to each trial a triple where the first number is the event time in samples. The second number is in most cases zero and can be ignored for this workshop. The third number is the event id, which we are most interessted in.\n",
    "\n",
    "E.g. for the first 10 trials this would look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8d9d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs.events[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350cebbf",
   "metadata": {},
   "source": [
    "To check which event ID corresponds to which condtion check epochs.event_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ea7528",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs.event_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668a47b4",
   "metadata": {},
   "source": [
    "In the first line of the next shell we extract the labels. As we saw right above, they are currently set to 201 and 202. We map them to 0 and 1 in the second line of the next shell, such that the class with more trials (*Standard*, assigned 201) will now correspond to 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6699ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = epochs.events[:,-1]\n",
    "labels = np.where(labels == 201, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f3c62b",
   "metadata": {},
   "source": [
    "### Exercise 2:\n",
    "How many trials are there of each condition?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da6ad7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75f084a3",
   "metadata": {},
   "source": [
    "We next create the train and test sets with a function from sklearn called [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html). As arguments give first the data, than the labels. We also set test_size=0.2 and random_state=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d95e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, labels_train, labels_test = train_test_split(...)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa1b8cc",
   "metadata": {},
   "source": [
    "### Exercise 3:\n",
    "What are the dimensions fo the train and test datasets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b08577",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2bbd9f0",
   "metadata": {},
   "source": [
    "## Creating a pipeline and fitting a first classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5be9ee6",
   "metadata": {},
   "source": [
    "Next, we will construct a pipeline for classification with the function [make_pipeline()](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html) of the sklearn library. We want to execute the following steps:\n",
    "1. We need to transform the EEG data from (n_epochs, n_channels, n_times) to (n_samples, n_features), as the classifier that we are going to use here is working with two dimensional input. This can be achieved with the [Vectorizer()](https://mne.tools/stable/generated/mne.decoding.Vectorizer.html) function of mne.\n",
    "2. Standardize our data, to compensate for differences in power of the EEG. I.e. we substract the mean ($\\mu$) from our original data ($x$) and devide by the standard deviation ($\\sigma$) to get the standardized data $z$: $z = (x - \\mu) / \\sigma$. \n",
    "\n",
    "    This can be achieved with the [StandardScaler()](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) function of mne. \n",
    "\n",
    "3. The last step will be the machine learning algorithm used for classification. We will use [Logistic Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.fit), with C=1 and penalty='l2. \n",
    "\n",
    "\n",
    "The final pipeline will look like this (where the order of functions again is very important):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cc59e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = make_pipeline(Vectorizer(), StandardScaler(), LogisticRegression(solver='liblinear', random_state=42, \n",
    "                                                                       penalty='l2', C=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f350dd24",
   "metadata": {},
   "source": [
    "Now we have everythin ready and can fit our classifier with the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a89407",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(train_data, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd495dc3",
   "metadata": {},
   "source": [
    "After training the classifier we evaluate the performance, first on the train set, by calculating the predicted labels for the train_data and then the [accuracy](accuracy_score) with the function from sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22d3c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(train_data)\n",
    "print(accuracy_score(labels_train, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553dda74",
   "metadata": {},
   "source": [
    "But it is easier, to use the function from sklearn to directly get the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4665c8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(train_data, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3af5994",
   "metadata": {},
   "source": [
    "### Exercise 4: \n",
    "The score for the train set is quite amazing. What is the classification score on the test dataset? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13754380",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07b81de6",
   "metadata": {},
   "source": [
    "As it was mentioned in the lecture, it is not very good to only do this once, on a single split of the data. So we would need to do the data spliting, fitting the classifers and evaluation multiple times. \n",
    "In stead we can also use a function from sklearn called [cross_val_score](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score) on the full data and labels, which does split the data multiple times (the number is given with the cv parameter) and calculates the scores automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1ed0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_cv = make_pipeline(Vectorizer(), StandardScaler(), LogisticRegression(solver='liblinear', \n",
    "                                                                          random_state=42, \n",
    "                                                                          penalty='l2', C=1))\n",
    "scores = cross_val_score(clf_cv, train_data, labels_train, cv=5)\n",
    "for i in range(len(scores)):   \n",
    "    print(f'Accuracy of {i}th fold is {scores[i] : .2f}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dedf820",
   "metadata": {},
   "source": [
    "## Optimizing the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495d9a36",
   "metadata": {},
   "source": [
    "In the above paradigm we just used a default implementation of Logistic Regression with a 'l2' metric and a hyperparameter C set to 1. Now we will estimate the parameters through exhaustive [Grid Search](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html), these parameters are oftentimes called hyperparameters.\n",
    "\n",
    "'GridSearchCV' exhaustively tests candidate models from a grid of parameter values specified in the following form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c931e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'penalty' : ['l1', 'l2'], 'C' : [1, 10, 100]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475a81ab",
   "metadata": {},
   "source": [
    "We include the Grid Search in the pipeline, in stead of Logistic Regression. The GridSearch object will take the classifier as an argument. And as you can see we also give again the cv argument, such that the parameters above can be evaluated on multiple different splits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ada21ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_opt = make_pipeline(Vectorizer(), StandardScaler(), GridSearchCV(LogisticRegression(solver='liblinear', \n",
    "                                                                                        random_state=42), \n",
    "                                                                     parameters, cv=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0f9769",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_opt.fit(train_data, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db101bd4",
   "metadata": {},
   "source": [
    "As before we can asses the performance of the train set with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a924eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_opt.score(train_data, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b8c6c4",
   "metadata": {},
   "source": [
    "### Exercise 5:\n",
    "What is the performance of the optimized classifier on the test set? Is this better then the one we used before?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a7dd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_opt.score(test_data, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21982325",
   "metadata": {},
   "source": [
    "We can extract the optimized parameters through:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0a5a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = clf_opt.steps[-1][1]\n",
    "tmp.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be7cdda",
   "metadata": {},
   "source": [
    "Please note, that this is only working on a classifier trained specifically. You can not extract the best parameters from the cross_val_score function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea63487",
   "metadata": {},
   "source": [
    "## A short note on Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa41581",
   "metadata": {},
   "source": [
    "What is the level of chance for the data that we are using?\n",
    "\n",
    "*Standard* has 127 trials and *Novel* has 27, which means that for a classifier always predicting *Standard* we get an accuracy of 127/(127+27) = 0.82! Which is around the same level, as the test score in Exercise 5.\n",
    "\n",
    "This means that for some cases, where we have extreamly unbalanced datasets, using accuracy to keep track of your performance is not an appropriate choice. We could for example use the [f1-score](https://en.wikipedia.org/wiki/F-score). For the above naive classifier, that always predicts *Standard*, the f1-score would be 0.\n",
    "\n",
    "Let's check out the f1-score of our classifer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272ac3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = clf_opt.predict(train_data)\n",
    "\n",
    "f1_score(labels_train, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8dbec0",
   "metadata": {},
   "source": [
    "### Exercise 6:\n",
    "What is the f1-score of the optimized classifier on the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9855258f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2248b59e",
   "metadata": {},
   "source": [
    "## Sliding Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a636fc80",
   "metadata": {},
   "source": [
    "In the steps above we were still evaluating a rather simplified version of our data, where we did not considered the temporal structure of EEG data. But considered all time points and electrodes simultaneously.  Now we will take the temporal dimension into account as well and will evaluate how classification accuracy changes across time. For this we will use the [SlidingEstimator](https://mne.tools/stable/generated/mne.decoding.SlidingEstimator.html) of mne:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52358671",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_tp = make_pipeline(Vectorizer(), StandardScaler(), LogisticRegression(solver='liblinear', \n",
    "                                                                          random_state=42, penalty='l1', \n",
    "                                                                          C=1))\n",
    "\n",
    "sl = SlidingEstimator(clf_tp, scoring=make_scorer(f1_score)) # we apply the sliding estimator to 'clf'\n",
    "sl.fit(train_data, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddbe57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_train = sl.score(train_data, labels_train)\n",
    "score_test = sl.score(test_data, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c4ba02",
   "metadata": {},
   "source": [
    "### Exercise 7:\n",
    "What are the dimensions of the classification scores? What do they represent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f0604a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d50383c4",
   "metadata": {},
   "source": [
    "We can now plot the classification accuracies across time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e03f9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5), dpi=300)\n",
    "ax.set_xlabel('Time (s)')\n",
    "ax.set_ylabel('Accuracy') \n",
    "ax.set_title('Decoding performance over time')\n",
    "ax.plot(epochs.times, score_train, color='blue', label='Train')\n",
    "ax.plot(epochs.times, score_test, color='red', label='Test')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e001a30",
   "metadata": {},
   "source": [
    "### Extracting the weights\n",
    "From each classifier we can extract the weights, representing how importent each electrode / time point is for the classification performance. The weights can be found as estimator.coef_ for all of the classifiers that we used above. \n",
    "\n",
    "In this example here, we will look at the Sliding Estimator classifers and extract the weights for the elextrodes per timepoint. Similar to the last part of the previous Jupyter notebook, we also copy the evoked structure, to asign the weights and plot them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0111b75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = epochs.times\n",
    "\n",
    "weights = copy.deepcopy(epochs.average())\n",
    "for tp in range(len(times)):\n",
    "    weights._data[:,tp] = sl.estimators_[tp].steps[-1][1].coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692d02d3",
   "metadata": {},
   "source": [
    "### Exercise 8:\n",
    "Plot the weights in a topographic map representation (see 'Part 1: About neural data') for the following timepoints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156fa600",
   "metadata": {},
   "outputs": [],
   "source": [
    "timepoints = np.arange(0, 0.51, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daffd61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcf79cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
